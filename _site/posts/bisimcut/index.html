<!doctype html>














<!-- `site.alt_lang` can specify a language different from the UI -->
<html lang="en" data-mode="light">
  <head>
  <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
  <meta name="theme-color" media="(prefers-color-scheme: light)" content="#f7f7f7">
  <meta name="theme-color" media="(prefers-color-scheme: dark)" content="#1b1b1e">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <meta
    name="viewport"
    content="width=device-width, user-scalable=no initial-scale=1, shrink-to-fit=no, viewport-fit=cover"
  ><!-- Setup Open Graph image -->

  

  <!-- Begin Jekyll SEO tag v2.8.0 -->
<meta name="generator" content="Jekyll v4.3.3" />
<meta property="og:title" content="(논문 리뷰) Bi-SimCut A Simple Strategy for Boosting Neural Machine Translation" />
<meta property="og:locale" content="en" />
<meta name="description" content="Abstract Bi-Simcut은 간단하지만 효과적인 training strategy 입니다. 이것은 두 단계로 구성 됩니다. 1. bidirectional pretraining 2. unidirectional finetuning. 두 단계 모두 original, cutoff sentence paris간의 output distributions의 consistency를 유지하게 하는 정규화 방법 SimCut을 적용 합니다. 이떄 back-translation으로 생성한 extra dataset이나 large-scale pretrained model은 사용하지 않고, Bi-SumCut은 강력한 translation performacne를 달성 하였습니다. Sim-Cut은 새로운 방법이 아니고, Cut-off (Shen et al. 2020)를 간단화하고 NMT에 적용한 방법 입니다." />
<meta property="og:description" content="Abstract Bi-Simcut은 간단하지만 효과적인 training strategy 입니다. 이것은 두 단계로 구성 됩니다. 1. bidirectional pretraining 2. unidirectional finetuning. 두 단계 모두 original, cutoff sentence paris간의 output distributions의 consistency를 유지하게 하는 정규화 방법 SimCut을 적용 합니다. 이떄 back-translation으로 생성한 extra dataset이나 large-scale pretrained model은 사용하지 않고, Bi-SumCut은 강력한 translation performacne를 달성 하였습니다. Sim-Cut은 새로운 방법이 아니고, Cut-off (Shen et al. 2020)를 간단화하고 NMT에 적용한 방법 입니다." />
<link rel="canonical" href="http://localhost:4000/posts/bisimcut/" />
<meta property="og:url" content="http://localhost:4000/posts/bisimcut/" />
<meta property="og:site_name" content="vhch" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2023-03-14T00:00:00+09:00" />
<meta name="twitter:card" content="summary" />
<meta property="twitter:title" content="(논문 리뷰) Bi-SimCut A Simple Strategy for Boosting Neural Machine Translation" />
<meta name="twitter:site" content="@twitter_username" />
<meta name="google-site-verification" content="nqMD8mOUs3m2jRGrMob_LZMp-dbKykPmIITCo3mKRe8" />
<script type="application/ld+json">
{"@context":"https://schema.org","@type":"BlogPosting","dateModified":"2023-03-14T00:00:00+09:00","datePublished":"2023-03-14T00:00:00+09:00","description":"Abstract Bi-Simcut은 간단하지만 효과적인 training strategy 입니다. 이것은 두 단계로 구성 됩니다. 1. bidirectional pretraining 2. unidirectional finetuning. 두 단계 모두 original, cutoff sentence paris간의 output distributions의 consistency를 유지하게 하는 정규화 방법 SimCut을 적용 합니다. 이떄 back-translation으로 생성한 extra dataset이나 large-scale pretrained model은 사용하지 않고, Bi-SumCut은 강력한 translation performacne를 달성 하였습니다. Sim-Cut은 새로운 방법이 아니고, Cut-off (Shen et al. 2020)를 간단화하고 NMT에 적용한 방법 입니다.","headline":"(논문 리뷰) Bi-SimCut A Simple Strategy for Boosting Neural Machine Translation","mainEntityOfPage":{"@type":"WebPage","@id":"http://localhost:4000/posts/bisimcut/"},"url":"http://localhost:4000/posts/bisimcut/"}</script>
<!-- End Jekyll SEO tag -->


  <title>(논문 리뷰) Bi-SimCut A Simple Strategy for Boosting Neural Machine Translation | vhch
  </title>

  <!--
  The Favicons for Web, Android, Microsoft, and iOS (iPhone and iPad) Apps
  Generated by: https://realfavicongenerator.net/
-->



<link rel="apple-touch-icon" sizes="180x180" href="/assets/img/favicons/apple-touch-icon.png">
<link rel="icon" type="image/png" sizes="32x32" href="/assets/img/favicons/favicon-32x32.png">
<link rel="icon" type="image/png" sizes="16x16" href="/assets/img/favicons/favicon-16x16.png">
<link rel="manifest" href="/assets/img/favicons/site.webmanifest">
<link rel="shortcut icon" href="/assets/img/favicons/favicon.ico">
<meta name="apple-mobile-web-app-title" content="vhch">
<meta name="application-name" content="vhch">
<meta name="msapplication-TileColor" content="#da532c">
<meta name="msapplication-config" content="/assets/img/favicons/browserconfig.xml">
<meta name="theme-color" content="#ffffff">


  
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
      <link rel="dns-prefetch" href="https://fonts.gstatic.com" crossorigin>
    
      <link rel="preconnect" href="https://fonts.googleapis.com" >
      <link rel="dns-prefetch" href="https://fonts.googleapis.com" >
    
      <link rel="preconnect" href="https://cdn.jsdelivr.net" >
      <link rel="dns-prefetch" href="https://cdn.jsdelivr.net" >
    

    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Lato&family=Source+Sans+Pro:wght@400;600;700;900&display=swap">
  

  <!-- GA -->
  

  <!-- Bootstrap -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@5.3.2/dist/css/bootstrap.min.css">

  <!-- Font Awesome -->
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@6.5.1/css/all.min.css">

  <link rel="stylesheet" href="/assets/css/jekyll-theme-chirpy.css">

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/tocbot@4.25.0/dist/tocbot.min.css">
  

  
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.min.css">
  

  
    <!-- Manific Popup -->
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/magnific-popup@1.1.0/dist/magnific-popup.min.css">
  

  <!-- JavaScript -->

  

  <!-- A placeholder to allow defining custom metadata -->

</head>


  <body>
    <!-- The Side Bar -->

<aside aria-label="Sidebar" id="sidebar" class="d-flex flex-column align-items-end">
  <header class="profile-wrapper">
    <a href="/" id="avatar" class="rounded-circle"></a>

    <h1 class="site-title">
      <a href="/">vhch</a>
    </h1>
    <p class="site-subtitle fst-italic mb-0"></p>
  </header>
  <!-- .profile-wrapper -->

  <nav class="flex-column flex-grow-1 w-100 ps-0">
    <ul class="nav">
      <!-- home -->
      <li class="nav-item">
        <a href="/" class="nav-link">
          <i class="fa-fw fas fa-home"></i>
          <span>HOME</span>
        </a>
      </li>
      <!-- the real tabs -->
      
        <li class="nav-item">
          <a href="/categories/" class="nav-link">
            <i class="fa-fw fas fa-stream"></i>
            

            <span>CATEGORIES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/tags/" class="nav-link">
            <i class="fa-fw fas fa-tags"></i>
            

            <span>TAGS</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/archives/" class="nav-link">
            <i class="fa-fw fas fa-archive"></i>
            

            <span>ARCHIVES</span>
          </a>
        </li>
        <!-- .nav-item -->
      
        <li class="nav-item">
          <a href="/about/" class="nav-link">
            <i class="fa-fw fas fa-info-circle"></i>
            

            <span>ABOUT</span>
          </a>
        </li>
        <!-- .nav-item -->
      
    </ul>
  </nav>

  <div class="sidebar-bottom d-flex flex-wrap  align-items-center w-100">
    

    
      

      
        <a
          href="https://github.com/vhch"
          aria-label="github"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fab fa-github"></i>
        </a>
      
    
      

      
        <a
          href="https://twitter.com/twitter_username"
          aria-label="twitter"
          

          
            target="_blank"
            
          

          

          
            rel="noopener noreferrer"
          
        >
          <i class="fa-brands fa-x-twitter"></i>
        </a>
      
    
      

      
        <a
          href="javascript:location.href = 'mailto:' + ['vhch66','gmail.com'].join('@')"
          aria-label="email"
          

          

          

          
        >
          <i class="fas fa-envelope"></i>
        </a>
      
    
      

      
        <a
          href="/feed.xml"
          aria-label="rss"
          

          

          

          
        >
          <i class="fas fa-rss"></i>
        </a>
      
    
  </div>
  <!-- .sidebar-bottom -->
</aside>
<!-- #sidebar -->


    <div id="main-wrapper" class="d-flex justify-content-center">
      <div class="container d-flex flex-column px-xxl-5">
        <!-- The Top Bar -->

<header id="topbar-wrapper" aria-label="Top Bar">
  <div
    id="topbar"
    class="d-flex align-items-center justify-content-between px-lg-3 h-100"
  >
    <nav id="breadcrumb" aria-label="Breadcrumb">
      

      
        
          
            <span>
              <a href="/">Home</a>
            </span>

          
        
          
        
          
            
              <span>(논문 리뷰) Bi-SimCut A Simple Strategy for Boosting Neural Machine Translation</span>
            

          
        
      
    </nav>
    <!-- endof #breadcrumb -->

    <button type="button" id="sidebar-trigger" class="btn btn-link">
      <i class="fas fa-bars fa-fw"></i>
    </button>

    <div id="topbar-title">
      Post
    </div>

    <button type="button" id="search-trigger" class="btn btn-link">
      <i class="fas fa-search fa-fw"></i>
    </button>

    <search class="align-items-center ms-3 ms-lg-0">
      <i class="fas fa-search fa-fw"></i>
      <input
        class="form-control"
        id="search-input"
        type="search"
        aria-label="search"
        autocomplete="off"
        placeholder="Search..."
      >
    </search>
    <button type="button" class="btn btn-link text-decoration-none" id="search-cancel">Cancel</button>
  </div>
</header>


        <div class="row flex-grow-1">
          <main aria-label="Main Content" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              <!-- Refactor the HTML structure -->



<!--
  In order to allow a wide table to scroll horizontally,
  we suround the markdown table with `<div class="table-wrapper">` and `</div>`
-->



<!--
  Fixed kramdown code highlight rendering:
  https://github.com/penibelst/jekyll-compress-html/issues/101
  https://github.com/penibelst/jekyll-compress-html/issues/71#issuecomment-188144901
-->



<!-- Change the icon of checkbox -->



<!-- Handle images -->




  
  

  
    
      
      
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  
    

    
    

    

    
    

    
    
    

    
      

      
      
      

      
    
      

      
      
      

      
    

    <!-- take out classes -->
    

    
    

    

    
      
    

    <!-- lazy-load images -->
    

    
      <!-- make sure the `<img>` is wrapped by `<a>` -->
      

      
        <!-- create the image wrapper -->
        

        
        
      
    

    <!-- combine -->
    
  

  


<!-- Add header for code snippets -->



<!-- Create heading anchors -->





  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  
    
    

    
      
        
        
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    
      

      
      

      
      
      

      
    

    
  

  
  

  

  
  

  




<!-- return -->




<article class="px-1">
  <header>
    <h1 data-toc-skip>(논문 리뷰) Bi-SimCut A Simple Strategy for Boosting Neural Machine Translation</h1>

    <div class="post-meta text-muted">
      <!-- published date -->
      <span>
        Posted
        <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1678719600"
  data-df="ll"
  
    data-bs-toggle="tooltip" data-bs-placement="bottom"
  
>
  Mar 14, 2023
</time>

      </span>

      <!-- lastmod date -->
      

      

      <div class="d-flex justify-content-between">
        <!-- author(s) -->
        <span>
          

          By

          <em>
            
              <a href="https://github.com/vhch">vhch</a>
            
          </em>
        </span>

        <!-- read time -->
        <!-- Calculate the post's reading time, and display the word count in tooltip -->



<!-- words per minute -->










<!-- return element -->
<span
  class="readtime"
  data-bs-toggle="tooltip"
  data-bs-placement="bottom"
  title="997 words"
>
  <em>5 min</em> read</span>

      </div>
      <!-- .d-flex -->
    </div>
    <!-- .post-meta -->
  </header>

  <div class="content">
    <h1 id="abstract">Abstract</h1>
<p>Bi-Simcut은 간단하지만 효과적인  training strategy 입니다. 이것은 두 단계로 구성 됩니다. 1. bidirectional pretraining 2. unidirectional finetuning. 두 단계 모두 original, cutoff sentence paris간의 output distributions의 consistency를 유지하게 하는 정규화 방법 SimCut을 적용 합니다. 이떄 back-translation으로 생성한 extra dataset이나 large-scale pretrained model은 사용하지 않고, Bi-SumCut은 강력한 translation performacne를 달성 하였습니다. Sim-Cut은 새로운 방법이 아니고, Cut-off (Shen et al. 2020)를 간단화하고 NMT에 적용한 방법 입니다.</p>

<h1 id="1-introduction">1 Introduction</h1>

<h2 id="연구-필요성"><span class="me-2">연구 필요성</span><a href="#연구-필요성" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ul>
  <li>기존 연구 simcut은 뛰어난 성능을 가짐</li>
  <li>하지만 연구에서 소개된 Hyperparameter 4개의 적절한 값을 찾는것은 지루하고 많은 시간이 소모됨.</li>
</ul>

<h2 id="연구-목표-및-내용"><span class="me-2">연구 목표 및 내용</span><a href="#연구-목표-및-내용" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ul>
  <li>NMT 교육을 위한 전략을 제공
    <ul>
      <li>간단하고 재현하기 쉽지만 효과적</li>
      <li>cutoff 참조</li>
      <li>virtual adversarial regularization 참조</li>
    </ul>
  </li>
  <li>SimCut 제안
    <ul>
      <li>새로운 방법 x</li>
      <li>Cutoff에서 제안된 Token Cutoff를 간소화 함</li>
      <li>bidirectional backpropagation in KL regularization이 key role임</li>
    </ul>
  </li>
  <li>Bi-SimCut 제안
    <ul>
      <li>SimCut은 perturbation based이면서 augmentation 방법임</li>
      <li>두 단계로 training strategy가 구성됨
        <ul>
          <li>bidirectional pretraining with SimCut</li>
          <li>unidirectional finetuning with SimCut</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="연구-contribution"><span class="me-2">연구 Contribution</span><a href="#연구-contribution" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ul>
  <li>SimCut 제안
    <ul>
      <li>perturbation based method로 간주 가능</li>
      <li>pretrained language models mBART에 대한 호환성을 보임</li>
    </ul>
  </li>
  <li>Bi-SimCut 제안
    <ul>
      <li>bidirectional pretraining, unidirectional finetuing with SimCut으로 구성</li>
    </ul>
  </li>
  <li>5가지 translation benchmark에서 인상적인 개선
    <ul>
      <li>Transforemr model with Bi-SimCut을 이용</li>
    </ul>
  </li>
</ul>

<h1 id="3-datasets-and-baseline-settings">3 Datasets and Baseline Settings</h1>

<h2 id="datasets"><span class="me-2">Datasets</span><a href="#datasets" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ul>
  <li>IWSLT14 en &lt;-&gt; de (low-resource)</li>
  <li>WMT17 zh -&gt; en  (high-resource)</li>
</ul>

<p><a href="/assets/img/bisimcut/1.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/1.PNG" alt="1.PNG" loading="lazy"></a></p>

<h2 id="settings"><span class="me-2">Settings</span><a href="#settings" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ul>
  <li>Base model = Transformer</li>
  <li>label smoothing = 0.1</li>
  <li>max tokens per batch = 4096</li>
  <li>Adam optimizer with Beta (0.9, 0.98)</li>
  <li>4000 warmup steps</li>
  <li>learning rate = 5e-4</li>
  <li>dropout rate = 0.3</li>
  <li>beam size = 5</li>
  <li>length penalty 1.0</li>
</ul>

<h1 id="4-bi-simcut">4 Bi-SimCut</h1>
<h2 id="41-simcut-a-simple-cutoff-regularization-for-nmt"><span class="me-2">4.1 SimCut: A Simple Cutoff Regularization for NMT</span><a href="#41-simcut-a-simple-cutoff-regularization-for-nmt" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<ul>
  <li>기존 cut off는 ($p_{cut}$, $\alpha$, $\beta$, N)의 parameter를 일일히 찾아야 함</li>
  <li>이러한 부담을 줄이기 위해서 SimCut 제안</li>
  <li>problem formulation는 Virtual Adversarial Training (VAT)에서 영감을 얻음
    <ul>
      <li>KL-based adversarial regularization</li>
      <li>adversarial perturbations $\delta_x \in \mathbb R^{d \times I}$, $\delta_y \in \mathbb R^{d \times J}$을 original sampels에 더한 것과 original samples의 차이를 줄임</li>
      <li>$KL(f(e(x), e(y); \theta , || f(e(x) + \delta_x, e(y) + \delta_y; \theta))$</li>
    </ul>
  </li>
  <li>Token Cutoff로 perturbation 생성
    <ul>
      <li>기존 VAT는 gradient 방식으로 perturbation 생성</li>
      <li>각 sentence pair (x, y)에서 하나의 cutoff smaple ($x_{cut}$, $y_{cut}$) 생성</li>
      <li>Training objective of Simcut
        <ul>
          <li>$L_{simcut}(\theta) = L_{ce}(\theta) + \alpha L_{simkl}(\theta)$</li>
          <li>$L_{simkl}(\theta)$ =  $KL(f(x, y; \theta \, || f(x_{cut}, y_{cut} ; \theta))$</li>
          <li>두개의 hyper-parameters $\alpha$, $p_{cut}$만 존재</li>
          <li>VAT는 KL의 오른쪽항에 대해서만 back propagation, BiSimCut은 왼, 오른쪽 모두 back propagation</li>
        </ul>
      </li>
    </ul>
  </li>
</ul>

<h2 id="42-analysis-on-simcut"><span class="me-2">4.2 Analysis on SimCut</span><a href="#42-analysis-on-simcut" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<h3 id="421-how-does-the-simplification-affect-performance"><span class="me-2">4.2.1 How Does the Simplification Affect Performance?</span><a href="#421-how-does-the-simplification-affect-performance" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><a href="/assets/img/bisimcut/2.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/2.PNG" alt="2.png" loading="lazy"></a></p>

<ul>
  <li>기존 방법보다 뛰어난 성능 달성</li>
</ul>

<p><a href="/assets/img/bisimcut/3.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/3.PNG" alt="3.png" loading="lazy"></a></p>

<ul>
  <li>training cost에 따른 성능 비교
    <ul>
      <li>VAT over fitting 발생</li>
      <li>SimCut은 much more training time to converge이지만 over fitting 덜 발생</li>
      <li>Token Cutoff costs about 148 seconds per epoch (N=1)</li>
      <li>Simcut costs about 128 seconds per epoch</li>
    </ul>
  </li>
</ul>

<h3 id="422-how-does-the-bidirectional-backpropagation-affect-performance"><span class="me-2">4.2.2 How Does the Bidirectional Backpropagation Affect Performance?</span><a href="#422-how-does-the-bidirectional-backpropagation-affect-performance" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>

<p><a href="/assets/img/bisimcut/4.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/4.PNG" alt="4.png" loading="lazy"></a></p>

<ul>
  <li>KL 항에서 양쪽항을 back propagation 할 떄의 효과</li>
  <li>Bi-backpropagation시 성능 증가</li>
</ul>

<h3 id="423-performance-on-perturbed-inputs"><span class="me-2">4.2.3 Performance on Perturbed Inputs</span><a href="#423-performance-on-perturbed-inputs" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>Simcut은 perturbation method로 간주 가능</li>
  <li>기존의 perturbation 방법과 비교</li>
  <li>확률 p ~ (0.00, 0.01, 0.05, 0.10)로 replace or drop된 문장으로 실험 진행</li>
</ul>

<p><a href="/assets/img/bisimcut/5.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/5.PNG" alt="5.png" loading="lazy"></a></p>

<p><a href="/assets/img/bisimcut/6.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/6.PNG" alt="6.png" loading="lazy"></a></p>

<ul>
  <li>SimCut이 perturbed test set에서 가장 robustness 함</li>
</ul>

<h3 id="424-effects-of-alpha-and-p_cut"><span class="me-2">4.2.4 Effects of $\alpha$ and $p_{cut}$</span><a href="#424-effects-of-alpha-and-p_cut" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>$\alpha \in {1, 2, 3, 4, 5}$</li>
  <li>$p_{cut} \in {0.00, 0.05, 0.10, 0.15, 0.20}$</li>
</ul>

<p><a href="/assets/img/bisimcut/7.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/7.PNG" alt="7.png" loading="lazy"></a></p>

<h3 id="425--is-simcut-compatible-with-the-pretrained-language-model"><span class="me-2">4.2.5  Is SimCut Compatible with the Pretrained Language Model?</span><a href="#425--is-simcut-compatible-with-the-pretrained-language-model" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h3>
<ul>
  <li>Backbone model : mBART</li>
  <li>dataset
    <ul>
      <li>IWSLT14 de-&gt;en</li>
      <li>only remove the duplicated sentence pairs following mBART50</li>
    </ul>
  </li>
  <li>Transformer
    <ul>
      <li>randonly initialized</li>
      <li>trained from scratch</li>
      <li>configurations in Section 3</li>
    </ul>
  </li>
  <li>mBART
    <ul>
      <li>directly finetuned from mBART</li>
    </ul>
  </li>
  <li>mBART with SimCut
    <ul>
      <li>finetuned from mBART with SimCut</li>
    </ul>
  </li>
</ul>

<p><a href="/assets/img/bisimcut/8.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/8.PNG" alt="8.PNG" loading="lazy"></a></p>

<h2 id="43-training-strategy--bidirectional-pretrain-and-unidriectional-finetune"><span class="me-2">4.3 Training Strategy : Bidirectional Pretrain and Unidriectional Finetune</span><a href="#43-training-strategy--bidirectional-pretrain-and-unidriectional-finetune" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<ul>
  <li>English -&gt; German dataset 존재</li>
  <li>English + German -&gt; German + English로 먼저 pre train</li>
  <li>이후 English -&gt; German으로 fine tunning</li>
</ul>

<p><a href="/assets/img/bisimcut/9.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/9.PNG" alt="9.PNG" loading="lazy"></a></p>

<p><a href="/assets/img/bisimcut/10.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/10.PNG" alt="10.PNG" loading="lazy"></a></p>

<h1 id="5-standard-resource-scenario">5 Standard Resource Scenario</h1>
<h2 id="51-dataset-description-and-model-configuration"><span class="me-2">5.1 Dataset Description and Model Configuration</span><a href="#51-dataset-description-and-model-configuration" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ul>
  <li>Dataset : WMT14 English-German (4.5M parallel sentence)</li>
  <li>Validation set : newstest2012, newstest2013</li>
  <li>Test set : newstest2014</li>
  <li>shard dictionary with 52K bpe</li>
  <li>Transformer Big model</li>
  <li>cross entropy loss with label smoothing rate 0.1</li>
  <li>max tokens per batch to be 4096</li>
  <li>Adam optimizer with Beta (0.9, 0.98)</li>
  <li>4000 warmup steps</li>
  <li>inverse square root learning rate scheduler with initial learning rates 1e-3</li>
  <li>decrease the learning rate to 5e-4</li>
  <li>dropout = [0.3, 0.2, 0.1]</li>
  <li>beam size = 4</li>
  <li>length penalty 0.6</li>
</ul>

<h2 id="52-results"><span class="me-2">5.2 Results</span><a href="#52-results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ul>
  <li>$p_{cut}$ = 0.05</li>
</ul>

<p><a href="/assets/img/bisimcut/11.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/11.PNG" alt="11.PNG" loading="lazy"></a></p>

<h1 id="6-high-resource-scenario">6 High Resource Scenario</h1>
<h2 id="61-dataset-description-and-model-configuration"><span class="me-2">6.1 Dataset Description and Model Configuration</span><a href="#61-dataset-description-and-model-configuration" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>
<ul>
  <li>Dataset : WMT17 Chinese-English dataset (20.2M training sentence pairs)</li>
  <li>Validation set : newsdev2017</li>
  <li>Test set : newstest2017</li>
  <li>32K BPE vocabularies</li>
  <li>Transformer Big model</li>
</ul>

<h2 id="62-results"><span class="me-2">6.2 Results</span><a href="#62-results" class="anchor text-muted"><i class="fas fa-hashtag"></i></a></h2>

<p><a href="/assets/img/bisimcut/12.PNG" class="popup img-link  shimmer"><img src="/assets/img/bisimcut/12.PNG" alt="12.PNG" loading="lazy"></a></p>

  </div>

  <div class="post-tail-wrapper text-muted">
    <!-- categories -->
    
      <div class="post-meta mb-3">
        <i class="far fa-folder-open fa-fw me-1"></i>
        
          <a href="/categories/nlp/">nlp</a>,
          <a href="/categories/translation/">translation</a>
      </div>
    

    <!-- tags -->
    
      <div class="post-tags">
        <i class="fa fa-tags fa-fw me-1"></i>
        
          <a
            href="/tags/deeplearning/"
            class="post-tag no-text-decoration"
          >deeplearning</a>
        
          <a
            href="/tags/nlp/"
            class="post-tag no-text-decoration"
          >nlp</a>
        
          <a
            href="/tags/transformer/"
            class="post-tag no-text-decoration"
          >transformer</a>
        
      </div>
    

    <div
      class="
        post-tail-bottom
        d-flex justify-content-between align-items-center mt-5 pb-2
      "
    >
      <div class="license-wrapper">
        
          

          This post is licensed under 
        <a href="https://creativecommons.org/licenses/by/4.0/">
          CC BY 4.0
        </a>
         by the author.
        
      </div>

      <!-- Post sharing snippet -->

<div class="share-wrapper d-flex align-items-center">
  <span class="share-label text-muted">Share</span>
  <span class="share-icons">
    
    
    

    

      

      <a href="https://twitter.com/intent/tweet?text=(%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0)%20Bi-SimCut%20A%20Simple%20Strategy%20for%20Boosting%20Neural%20Machine%20Translation%20-%20vhch&url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fbisimcut%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Twitter" aria-label="Twitter">
        <i class="fa-fw fa-brands fa-square-x-twitter"></i>
      </a>
    

      

      <a href="https://www.facebook.com/sharer/sharer.php?title=(%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0)%20Bi-SimCut%20A%20Simple%20Strategy%20for%20Boosting%20Neural%20Machine%20Translation%20-%20vhch&u=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fbisimcut%2F" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Facebook" aria-label="Facebook">
        <i class="fa-fw fab fa-facebook-square"></i>
      </a>
    

      

      <a href="https://t.me/share/url?url=http%3A%2F%2Flocalhost%3A4000%2Fposts%2Fbisimcut%2F&text=(%EB%85%BC%EB%AC%B8%20%EB%A6%AC%EB%B7%B0)%20Bi-SimCut%20A%20Simple%20Strategy%20for%20Boosting%20Neural%20Machine%20Translation%20-%20vhch" target="_blank" rel="noopener" data-bs-toggle="tooltip" data-bs-placement="top" title="Telegram" aria-label="Telegram">
        <i class="fa-fw fab fa-telegram"></i>
      </a>
    

    <button
      id="copy-link"
      aria-label="Copy link"
      class="btn small"
      data-bs-toggle="tooltip"
      data-bs-placement="top"
      title="Copy link"
      data-title-succeed="Link copied successfully!"
    >
      <i class="fa-fw fas fa-link pe-none fs-6"></i>
    </button>
  </span>
</div>

    </div>
    <!-- .post-tail-bottom -->
  </div>
  <!-- div.post-tail-wrapper -->
</article>


            
          </main>

          <!-- panel -->
          <aside aria-label="Panel" id="panel-wrapper" class="col-xl-3 ps-2 mb-5 text-muted">
            <div class="access">
              <!-- Get 5 last posted/updated posts -->














  <section id="access-lastmod">
    <h2 class="panel-heading">Recently Updated</h2>
    <ul class="content list-unstyled ps-0 pb-1 ms-1 mt-2">
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/bisimcut/">(논문 리뷰) Bi-SimCut A Simple Strategy for Boosting Neural Machine Translation</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/unidrop/">(논문 리뷰) UniDrop A Simple yet Effective Technique to Improve Transformer without Extra Cost</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/cutoff/">(논문 리뷰) A Simple but Tough-to-Beat Data Augmentation Approach for Natural Language Understanding and Generation</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/rdrop/">(논문 리뷰) R-Drop, Regularized Dropout for Neural Networks</a>
        </li>
      
        
        
        
        <li class="text-truncate lh-lg">
          <a href="/posts/bibert/">(논문 리뷰) BERT, MBERT, or BIBERT? A Study on Contextualized Embeddings for Neural Machine Translation</a>
        </li>
      
    </ul>
  </section>
  <!-- #access-lastmod -->


              <!-- The trending tags list -->















  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deeplearning/">deeplearning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/nlp/">nlp</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/transformer/">transformer</a>
      
    </div>
  </section>


            </div>

            
              
              



  <section id="toc-wrapper" class="ps-0 pe-4">
    <h2 class="panel-heading ps-3 pt-2 mb-2">Contents</h2>
    <nav id="toc"></nav>
  </section>


            
          </aside>
        </div>

        <div class="row">
          <!-- tail -->
          <div id="tail-wrapper" class="col-12 col-lg-11 col-xl-9 px-md-4">
            
              
              <!-- Recommend the other 3 posts according to the tags and categories of the current post. -->

<!-- The total size of related posts -->


<!-- An random integer that bigger than 0 -->


<!-- Equals to TAG_SCORE / {max_categories_hierarchy} -->














  

  

  

  

  

  

  

  
    
  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  

  











  <aside id="related-posts" aria-labelledby="related-label">
    <h3 class="mb-4" id="related-label">Further Reading</h3>
    <nav class="row row-cols-1 row-cols-md-2 row-cols-xl-3 g-4 mb-4">
      
        <article class="col">
          <a href="/posts/bibert/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1674054000"
  data-df="ll"
  
>
  Jan 19, 2023
</time>

              <h4 class="pt-0 my-2">(논문 리뷰) BERT, MBERT, or BIBERT? A Study on Contextualized Embeddings for Neural Machine Translation</h4>
              <div class="text-muted">
                <p>
                  





                  1. Introduction
Pre-trained language models들은 large-scale unlabeled data에서 훈련합니다. ELMo, BERT, XLNET, XLM 등이 존재하고 다양한 NLP tasks에서 뛰어난 성능을 보이고 있습니다. 뛰어난 성능을 보이는 BERT의 pre-trained 모델을 translation mode...
                </p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/rdrop/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1675177200"
  data-df="ll"
  
>
  Feb  1, 2023
</time>

              <h4 class="pt-0 my-2">(논문 리뷰) R-Drop, Regularized Dropout for Neural Networks</h4>
              <div class="text-muted">
                <p>
                  





                  Abstract
Dropout은 deep neural networks을 train 할 때 강력하고 넓은 범위에  regularize 할 수 있는 방법 입니다. 하지만 random 적인 요소로 인해서 train과 inference 과정 사이에 inconsistency가 있을 수 있습니다. 본 논문에서는 regularize dropout을 위한 간단한 c...
                </p>
              </div>
            </div>
          </a>
        </article>
      
        <article class="col">
          <a href="/posts/cutoff/" class="post-preview card h-100">
            <div class="card-body">
              <!--
  Date format snippet
  See: ${JS_ROOT}/utils/locale-dateime.js
-->




<time
  
  data-ts="1678287600"
  data-df="ll"
  
>
  Mar  9, 2023
</time>

              <h4 class="pt-0 my-2">(논문 리뷰) A Simple but Tough-to-Beat Data Augmentation Approach for Natural Language Understanding and Generation</h4>
              <div class="text-muted">
                <p>
                  





                  1 Introduction

연구 필요성
massive unlabeld text corpora로 self-supervised training한 Large-scale language models로 pre-trained함. 특정한 task에 적용 하려면 task-specific data에 fine tunning 해야 함. 이때 거대한 model param...
                </p>
              </div>
            </div>
          </a>
        </article>
      
    </nav>
  </aside>
  <!-- #related-posts -->


            
              
              <!-- Navigation buttons at the bottom of the post. -->

<nav class="post-navigation d-flex justify-content-between" aria-label="Post Navigation">
  
  

  
    <a
      href="/posts/cutoff/"
      class="btn btn-outline-primary"
      aria-label="Older"
    >
      <p>(논문 리뷰) A Simple but Tough-to-Beat Data Augmentation Approach for Natural Language Understanding and Generation</p>
    </a>
  

  
    <a
      href="/posts/unidrop/"
      class="btn btn-outline-primary"
      aria-label="Newer"
    >
      <p>(논문 리뷰) UniDrop A Simple yet Effective Technique to Improve Transformer without Extra Cost</p>
    </a>
  
</nav>

            
              
              <!--  The comments switcher -->


            

            <!-- The Footer -->

<footer
  aria-label="Site Info"
  class="
    d-flex flex-column justify-content-center text-muted
    flex-lg-row justify-content-lg-between align-items-lg-center pb-lg-3
  "
>
  <p>©
    <time>2024</time>

    
      <a href="https://github.com/vhch">vhch</a>.
    

    
      <span
        data-bs-toggle="tooltip"
        data-bs-placement="top"
        title="Except where otherwise noted, the blog posts on this site are licensed under the Creative Commons Attribution 4.0 International (CC BY 4.0) License by the author."
      >Some rights reserved.</span>
    
  </p>

  <p>
  </p>
</footer>

          </div>
        </div>

        <!-- The Search results -->

<div id="search-result-wrapper" class="d-flex justify-content-center unloaded">
  <div class="col-11 content">
    <div id="search-hints">
      <!-- The trending tags list -->















  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
      
        
        

  
    
    
    
    
      
    
  
    
    
    
    
      
    
  
    
    
    
    
      
        
        



  <section>
    <h2 class="panel-heading">Trending Tags</h2>
    <div class="d-flex flex-wrap mt-3 mb-1 me-3">
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/deeplearning/">deeplearning</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/nlp/">nlp</a>
      
        
        <a class="post-tag btn btn-outline-primary" href="/tags/transformer/">transformer</a>
      
    </div>
  </section>


    </div>
    <div id="search-results" class="d-flex flex-wrap justify-content-center text-muted mt-3"></div>
  </div>
</div>

      </div>

      <aside aria-label="Scroll to Top">
        <button id="back-to-top" type="button" class="btn btn-lg btn-box-shadow">
          <i class="fas fa-angle-up"></i>
        </button>
      </aside>
    </div>

    <div id="mask"></div>

    
      <aside
  id="notification"
  class="toast"
  role="alert"
  aria-live="assertive"
  aria-atomic="true"
  data-bs-animation="true"
  data-bs-autohide="false"
>
  <div class="toast-header">
    <button
      type="button"
      class="btn-close ms-auto"
      data-bs-dismiss="toast"
      aria-label="Close"
    ></button>
  </div>
  <div class="toast-body text-center pt-0">
    <p class="px-2 mb-3">A new version of content is available.</p>
    <button type="button" class="btn btn-primary" aria-label="Update">
      Update
    </button>
  </div>
</aside>

    

    <!-- JavaScripts -->

    <!-- JS selector for site. -->

<!-- commons -->



<!-- layout specified -->


  

  
    <!-- image lazy-loading & popup & clipboard -->
    
  















  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  

  
    

    

  



  <script src="https://cdn.jsdelivr.net/combine/npm/jquery@3.7.1/dist/jquery.min.js,npm/bootstrap@5.3.2/dist/js/bootstrap.bundle.min.js,npm/simple-jekyll-search@1.10.0/dest/simple-jekyll-search.min.js,npm/loading-attribute-polyfill@2.1.1/dist/loading-attribute-polyfill.umd.min.js,npm/magnific-popup@1.1.0/dist/jquery.magnific-popup.min.js,npm/clipboard@2.0.11/dist/clipboard.min.js,npm/dayjs@1.11.10/dayjs.min.js,npm/dayjs@1.11.10/locale/en.min.js,npm/dayjs@1.11.10/plugin/relativeTime.min.js,npm/dayjs@1.11.10/plugin/localizedFormat.min.js,npm/tocbot@4.25.0/dist/tocbot.min.js,npm/mermaid@10.6.1/dist/mermaid.min.js"></script>






<script defer src="/assets/js/dist/post.min.js"></script>


  <!-- MathJax -->
  <script>
    /* see: <https://docs.mathjax.org/en/latest/options/input/tex.html#tex-options> */
    MathJax = {
      tex: {
        /* start/end delimiter pairs for in-line math */
        inlineMath: [
          ['$', '$'],
          ['\\(', '\\)']
        ],
        /* start/end delimiter pairs for display math */
        displayMath: [
          ['$$', '$$'],
          ['\\[', '\\]']
        ]
      }
    };
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-chtml.js"></script>





    
      <!-- mermaid-js loader -->
<script type="text/javascript">
  (function () {
    function updateMermaid(event) {
      if (event.source === window && event.data && event.data.direction === ModeToggle.ID) {
        const mode = event.data.message;

        if (typeof mermaid === 'undefined') {
          return;
        }

        let expectedTheme = mode === ModeToggle.DARK_MODE ? 'dark' : 'default';
        let config = { theme: expectedTheme };

        /* Re-render the SVG › <https://github.com/mermaid-js/mermaid/issues/311#issuecomment-332557344> */
        $('.mermaid').each(function () {
          let svgCode = $(this).prev().children().html();
          $(this).removeAttr('data-processed');
          $(this).html(svgCode);
        });

        mermaid.initialize(config);
        mermaid.init(undefined, '.mermaid');
      }
    }

    let initTheme = 'default';
    const html = document.documentElement;

    if (
      (html.hasAttribute('data-mode') && html.getAttribute('data-mode') === 'dark') ||
      (!html.hasAttribute('data-mode') && window.matchMedia('(prefers-color-scheme: dark)').matches)
    ) {
      initTheme = 'dark';
    }

    let mermaidConf = {
      theme: initTheme /* <default|dark|forest|neutral> */
    };

    /* Create mermaid tag */
    document.querySelectorAll('pre>code.language-mermaid').forEach((elem) => {
      const svgCode = elem.textContent;
      const backup = elem.parentElement;
      backup.classList.add('unloaded');
      /* create mermaid node */
      let mermaid = document.createElement('pre');
      mermaid.classList.add('mermaid');
      const text = document.createTextNode(svgCode);
      mermaid.appendChild(text);
      backup.after(mermaid);
    });

    mermaid.initialize(mermaidConf);

    window.addEventListener('message', updateMermaid);
  })();
</script>

    

    <!--
  Jekyll Simple Search loader
  See: <https://github.com/christian-fei/Simple-Jekyll-Search>
-->





<script>
  /* Note: dependent library will be loaded in `js-selector.html` */
  SimpleJekyllSearch({
    searchInput: document.getElementById('search-input'),
    resultsContainer: document.getElementById('search-results'),
    json: '/assets/js/data/search.json',
    searchResultTemplate: '  <article class="px-1 px-sm-2 px-lg-4 px-xl-0">    <header>      <h2><a href="{url}">{title}</a></h2>      <div class="post-meta d-flex flex-column flex-sm-row text-muted mt-1 mb-1">        {categories}        {tags}      </div>    </header>    <p>{snippet}</p>  </article>',
    noResultsText: '<p class="mt-5"></p>',
    templateMiddleware: function(prop, value, template) {
      if (prop === 'categories') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div class="me-sm-4"><i class="far fa-folder fa-fw"></i>${value}</div>`;
        }
      }

      if (prop === 'tags') {
        if (value === '') {
          return `${value}`;
        } else {
          return `<div><i class="fa fa-tag fa-fw"></i>${value}</div>`;
        }
      }
    }
  });
</script>

  </body>
</html>

